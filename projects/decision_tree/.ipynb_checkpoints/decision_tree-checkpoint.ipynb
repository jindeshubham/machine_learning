{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using decision Tree to solve Titanic survival datset \n",
    "\n",
    "Import the necessary libraries \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/train.csv')\n",
    "test_data  = pd.read_csv('./data/test.csv')\n",
    "\n",
    "complete_data = [train_data,test_data]\n",
    "passenger_id = test_data['PassengerId']\n",
    "\n",
    "#Keep the original data\n",
    "original_train = train_data.copy()\n",
    "original_train = test_data.copy()\n",
    "\n",
    "train_data['Cabin'] = train_data['Cabin'].apply(lambda x:0 if type(x)==float else 1)\n",
    "test_data['Cabin']  = test_data['Cabin'].apply(lambda x:0 if type(x)==float else 1)\n",
    "\n",
    "for data in complete_data:\n",
    "    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
    "    \n",
    "    data['Embarked'] = data['Embarked'].fillna('S')\n",
    "    \n",
    "    data['Fare'] = data['Fare'].fillna(train['Fare'].median())\n",
    "\n",
    "for data in complete_data:\n",
    "    avg_age = data['Age'].mean()\n",
    "    std_age = data['Age'].std()\n",
    "    null_age_count = data['Age'].isnull().sum()\n",
    "    random_age_list = np.random.randint(avg_age-std_age,avg_age+std_age,null_age_count)\n",
    "    data.loc[np.isnan(data['Age']), 'Age'] = random_age_list\n",
    "    data['Age'] = data['Age'].astype(int)\n",
    "\n",
    "def get_title(name):\n",
    "    title_search = re.search('([A-Za-z]+)\\.',name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    else :\n",
    "        return \"\"\n",
    "    \n",
    "for data in complete_data:\n",
    "    data['Title'] = data['Name'].apply(get_title)\n",
    "    \n",
    "for dataset in complete_data:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "for dataset in complete_data:\n",
    "    dataset['Sex'] = dataset['Sex'].map({\"male\":1,\"female\":0})\n",
    "    title_mapping = {\"Mr\": 1, \"Master\": 2, \"Mrs\": 3, \"Miss\": 4, \"Rare\": 5}\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "    \n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare']                               = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    # Mapping Age\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age']                          = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] ;\n",
    "    \n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \n",
    "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\n",
    "train = train_data.drop(drop_elements, axis = 1)\n",
    "test  = test_data.drop(drop_elements, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding best depth with the help of Cross Validation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the important part of building decision tree. We need to find the tree with the depth, such that it \n",
    "fits the data without overfitting. We will try depths from 1 to max features and use the tree with the depth \n",
    "that gives best validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Max Depth  Accuracy\n",
      "0           1  0.782267\n",
      "1           2  0.806583\n",
      "2           3  0.829405\n",
      "3           4  0.836139\n",
      "4           5  0.847363\n",
      "5           6  0.861081\n",
      "6           7  0.873551\n",
      "7           8  0.881906\n",
      "8           9  0.887767\n",
      "9          10  0.890760\n",
      "10         11  0.893129\n",
      "11         12  0.894625\n",
      "12         13  0.896122\n"
     ]
    }
   ],
   "source": [
    "cv =KFold(n_splits=10)\n",
    "accuracies = list()\n",
    "max_attributes = len(list(test_data))\n",
    "depth_range = range(1,max_attributes+1)\n",
    "\n",
    "for depth in depth_range:\n",
    "    fold_accuraacy= []\n",
    "    tree_model = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "    for train_fold, valid_fold in cv.split(train):\n",
    "        f_train = train.loc[train_fold] # Extract train data with cv indices\n",
    "        f_valid = train.loc[valid_fold]\n",
    "        \n",
    "        model = tree_model.fit(X = f_train.drop(['Survived'], axis=1), \n",
    "                               y = f_train[\"Survived\"]) \n",
    "        val_score = model.score(X = f_train.drop(['Survived'], axis=1), \n",
    "                               y = f_train[\"Survived\"]) \n",
    "        \n",
    "        fold_accuraacy.append(val_score)\n",
    "        \n",
    "    avg = sum(fold_accuraacy)/len(fold_accuraacy)\n",
    "    accuracies.append(avg)\n",
    "df =pd.DataFrame({\"Max Depth\":depth_range,\"Accuracy\":accuracies})  \n",
    "df = df[[\"Max Depth\",\"Accuracy\"]]\n",
    "print (df.to_string())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
